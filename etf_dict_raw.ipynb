{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "876b7810",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Embeddings = turning text to vectors (a way to compress text into something more easily searchable)\n",
    "FAISS = FB's vector database\n",
    "VectorDBQA = class that takes a pre-trained language model and a vector database and does Q&A stuff\n",
    "get_openai_callback = a way to get token info (aka OpenAI 'calls back' what it used)\n",
    "pickle is for saving and opening the vector database (so i dont have to calculate it for every question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aaab782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms.loading import load_llm\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "import os\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI, VectorDBQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pickle\n",
    "\n",
    "openai_api_key=\"API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5410a509",
   "metadata": {},
   "source": [
    "## Taking Text and turning it into a vector DB (and saving that to a file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66767f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '/Users/sommohapatra/Desktop/AI Stuff/ETF_Dictionary/text files'\n",
    "files = [f for f in os.listdir(dir_path) if f.endswith('.txt')]\n",
    "file_contents = []\n",
    "\n",
    "# Aggregate the contents of all txt files into a single string\n",
    "aggregated_text = \"\"\n",
    "for file in files:\n",
    "    with open(os.path.join(dir_path, file), \"r\") as f:\n",
    "        file_contents.append(f.read())\n",
    "\n",
    "metadatas = [{\"title\": f} for f in files if f.endswith('.txt')]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents = text_splitter.create_documents([f for f in file_contents], metadatas=metadatas)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "docsearch = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "with open(\"vectordb.pkl\", 'wb') as f:\n",
    "    pickle.dump(docsearch, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ead9d3",
   "metadata": {},
   "source": [
    "## Starting the model\n",
    "\n",
    "Chain types: stuff, map_reduce, map_rerank, refine.\n",
    "\n",
    "Not sure which is best for what yet. Performance for question-answering seems to be: stuff, refine, map_reduce, map_rerank\n",
    "\n",
    "Potential use-cases (GPT-generated, so take with grain of salt):\n",
    "- *Stuff* is designed to concatenate multiple texts together, rather than generating new text (it just stuffs all the related data into the prompt for the LLM to handle). Simple and brute-force (goes over LLM limit sometimes)\n",
    "\n",
    "- *Map-Reduce* is for large datasets. It takes two steps, the first generating intermediate outputs (aka applying the prompt/query to each chunk - calling LLM each time), and the second reducing those to a single one\n",
    "\n",
    "- *Refine* is iterative - taking one input chunk and applying the prompt, then doing so for the next input chunk and asking the LLM to refine. Well-suited for datasets that require a high level of precision and control. Takes more time and involves more LLM calls than *stuff* chain\n",
    "\n",
    "- *Map-Rerank* runs the prompt/query on each chunk, then scores the answer from the chunk on certainty. Returns the most certain response. Can't combine information between documents though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa7f170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = load_llm(\"llm.json\")\n",
    "\n",
    "qa_chain = load_qa_chain(llm, chain_type=\"refine\")\n",
    "\n",
    "with open(\"vectordb.pkl\", 'rb') as f:\n",
    "    docsearch = pickle.load(f)\n",
    "    \n",
    "qa = VectorDBQA(combine_documents_chain=qa_chain, vectorstore=docsearch, return_source_documents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6548330",
   "metadata": {},
   "source": [
    "## Querying the Question-Answering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7842a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Answer with as much detail as possible. If you do not know the answer, say 'I don't know':\"\n",
    "query = f\"{template} In bullet point format, what are all the costs of launching an ETF?\"\n",
    "result = qa({\"query\": query})\n",
    "answer = result['result']\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec343f9a",
   "metadata": {},
   "source": [
    "## Get source documents for answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9123d966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='We get the following question at least 1x a day: “How do I start an ETF?“\\nThe good news is we can help you access the ETF market with a low-cost high-quality service offering that spans the complexity spectrum from standard ETF launches to highly complex tax-free conversion transactions.\\nThe bad news is launching an ETF is an inherently challenging task with a lot of moving parts. However, this post is meant to be a resource that will help you become an educated consumer that has the capacity to make an informed decision.\\nAs many readers are aware, we are active in the so-called “ETF white-label” business via ETF Architect. We hope this is helpful and if there are additional questions/thoughts you’d like us to add — contact us — we’ll add them to the list.(1)\\nYou want to start an ETF…are you sure that’s a good idea?\\nWe have a good assortment of materials that address most questions we hear regarding ETF formations:\\n- An Introduction to ETF White Label Services', lookup_str='', metadata={'title': 'how_to_start_an_etf.txt'}, lookup_index=0),\n",
       " Document(page_content='Any advice or recommendations you can offer asset managers with ETFs or thinking about launching an ETF?\\nPrendergast: If starting out, begin with an investment strategy that has a strong track record and where you have a proven area of expertise. Know your target audience and have a plan of how you will gain/attract assets. Understand how you will market and sell your product through new distribution channels in advance.\\nConsider potential new hires that have ETF operations, sales, and distribution experience. Pick your service providers early in the process. They are an important part of any successful launch. Leverage their deep industry expertise, their ability to provide you with key industry introductions, share in industry best practices, and they can help keep you on track for a timely and efficient ETF launch.', lookup_str='', metadata={'title': 'mechanics_of_launching_2.txt'}, lookup_index=0),\n",
       " Document(page_content='Meb: So I get this question, if not every day, certainly every week, where someone will email me and say, “Hey, Meb. I’ve got this great idea. I’m ready to launch an ETF, how do I go about it?” And we have an old post that’s probably six, seven years old now, about how to start an ETF, and the new [inaudible 00:06:42] definitive guide, which we’ll put in the show-note links. But figured I can now point them to this podcast, because this will be a master class, and everything that goes into starting a fund: the drawbacks, the benefits, the pot of gold at the end of the rainbow. I think it’d be instructive or helpful to hear a little bit about how you guys decided to start launching ETFs from the early days, what was the on-ramp. And then, we’ll get really deep into the specifics on how all the sausage gets made.', lookup_str='', metadata={'title': 'etf_centralizes_everything_into_one_product.txt'}, lookup_index=0),\n",
       " Document(page_content='We asked Michael questions to tap into his knowledge and insights that can help asset managers and RIAs analyze the opportunities available and understand the dynamics of the ETF marketplace. As the ETF industry continues to evolve, it is important to understand the structural differences, regulations, and distribution landscape for launching an ETF product.]\\nBill Hortz: What do you feel is behind the increasing demand you are seeing from new and established investment managers looking to expand their portfolio offerings into ETFs?', lookup_str='', metadata={'title': 'mechanics_of_launching_1.txt'}, lookup_index=0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['source_documents']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab53574",
   "metadata": {},
   "source": [
    "## Generating Journal Entries from Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dfc289a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Scene opens with Finn and Jake walking through a forest. They come to a clearing and see a battlefield in the distance.]\n",
      "Finn: Whoa! This is it!\n",
      "Jake: Yeah, looks like it.\n",
      "[They approach the battlefield and see two armies facing each other.]\n",
      "Finn: So this is the Civil War, huh?\n",
      "Jake: Sure looks like it.\n",
      "[They approach the front lines of the armies. A soldier notices them and runs up to them.]\n",
      "Soldier: Hey, what are you two doing here?\n",
      "Finn: We're just here to watch.\n",
      "Soldier: Watch? This isn't a show! This is a real war!\n",
      "Jake: We know. We just want to observe.\n",
      "[The soldier looks to his commanding officer for direction. The officer nods, and the soldier steps aside.]\n",
      "Soldier: Alright. But you better stay out of the way.\n",
      "[Finn and Jake move to the side of the battlefield and watch as the armies charge each other. The battle is fierce and chaotic. Finn and Jake watch in awe as the armies clash. After what seems like an eternity, the battle is over. The Union army emerges victorious.]\n",
      "Finn: Wow. That was intense.\n",
      "Jake: Yeah, I can't believe we just witnessed a real Civil War battle.\n",
      "[Suddenly, a voice calls out from behind them.]\n",
      "Voice: Hey! You two!\n",
      "[They turn around and see an old man with a long beard. He is wearing a tattered uniform.]\n",
      "Old Man: I'm General Lee. What were you two doing here?\n",
      "Finn: Just watching.\n",
      "General Lee: Watching? This is a war! You two should be out there fighting!\n",
      "Jake: But we're not soldiers.\n",
      "General Lee: That doesn't mean you can't fight. Everyone can fight for what they believe in. Now go out there and do your part.\n",
      "[Finn and Jake look at each other, then back at the General. They nod and run off to join the battle.]\n",
      "[Fade to black.]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "with open(\"vectordb.pkl\", 'rb') as f:\n",
    "    search_index = pickle.load(f)\n",
    "\n",
    "prompt_template = \"\"\"Use the context below to write a 100 word episode script with the following general plot:\n",
    "    Context: {context}\n",
    "    Plot: {plot}\n",
    "    Script:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"plot\"]\n",
    ")\n",
    "\n",
    "llm = load_llm(\"llm_story.json\")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT)\n",
    "\n",
    "def generate_script(plot):\n",
    "    docs = search_index.similarity_search(plot, k=1)\n",
    "    inputs = [{\"context\": doc.page_content, \"plot\": plot} for doc in docs]\n",
    "    return chain.apply(inputs)\n",
    "\n",
    "\n",
    "script = generate_script(\"Finn and Jake find themselves in the middle of the Civil War.\")\n",
    "script = script[0]['text'].split(\"\\n\")\n",
    "print(*script, sep=\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
